{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Finetune LLM (Llama 3-8B-Instruct)"]},{"cell_type":"markdown","metadata":{},"source":["## Installing and importing requirements"]},{"cell_type":"markdown","metadata":{},"source":["This notebook was runned on Kaggle. So, make sure to run it on Kaggle, and as a result, the required libraries will be the following along with the ones that are already installed in the Kaggle environment."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:04:48.523519Z","iopub.status.busy":"2024-07-05T09:04:48.523180Z","iopub.status.idle":"2024-07-05T09:05:02.547808Z","shell.execute_reply":"2024-07-05T09:05:02.546725Z","shell.execute_reply.started":"2024-07-05T09:04:48.523489Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: peft in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (0.11.1)\n","Requirement already satisfied: numpy>=1.17 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (24.0)\n","Requirement already satisfied: psutil in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (5.9.8)\n","Requirement already satisfied: pyyaml in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (2.2.2)\n","Requirement already satisfied: transformers in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (4.42.2)\n","Requirement already satisfied: tqdm in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (0.31.0)\n","Requirement already satisfied: safetensors in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (0.4.3)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from peft) (0.23.4)\n","Requirement already satisfied: filelock in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\n","Requirement already satisfied: requests in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n","Requirement already satisfied: sympy in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: jinja2 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.3)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from transformers->peft) (2024.4.28)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /Users/arshandalili/Desktop/semantic-plausibility/.venv/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["! pip install -U autotrain-advanced > install_logs.txt 2>&1\n","! pip install peft"]},{"cell_type":"code","execution_count":24,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-05T09:40:29.933571Z","iopub.status.busy":"2024-07-05T09:40:29.933207Z","iopub.status.idle":"2024-07-05T09:40:29.938941Z","shell.execute_reply":"2024-07-05T09:40:29.938052Z","shell.execute_reply.started":"2024-07-05T09:40:29.933541Z"},"trusted":true},"outputs":[],"source":["import os\n","from huggingface_hub import notebook_login\n","import torch\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    pipeline,\n",")\n","from peft import LoraConfig, PeftModel\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm, trange\n","from sklearn.metrics import classification_report"]},{"cell_type":"markdown","metadata":{},"source":["Since we are using the Llama 3 model, you will need to have access to this model in order to run this notebook. When you have been granted access to the model, you need to enter your HF access token by running the following cell."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:05:08.728369Z","iopub.status.busy":"2024-07-05T09:05:08.727761Z","iopub.status.idle":"2024-07-05T09:05:08.750415Z","shell.execute_reply":"2024-07-05T09:05:08.749508Z","shell.execute_reply.started":"2024-07-05T09:05:08.728337Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b59a4bfd452d431d95d7e6f00575cee2","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["notebook_login()"]},{"cell_type":"markdown","metadata":{},"source":["## Fine-tune LLM"]},{"cell_type":"markdown","metadata":{},"source":["Here, we finetune the LLM on our dataset. We are using the AutoTrain framework to finetune the model. Please pay attention to the following notes:\n","\n","- The model is finetuned on the `train.csv` file ([link](https://github.com/arshandalili/semantic-plausibility/blob/main/models/Fine-tuned%20LLM/train.csv)), which MUST be in the `data` directory in the current working directory.\n","- Please enter your HF access token and HF username in the `hf_token` and `hf_username` variables.\n","- The model is finetuned for 8 epochs. You can change this by changing the `num_train_epochs` variable.\n","- Also, feel free to change other hyperparameters as you see fit."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["! autotrain setup --colab > setup_logs.txt\n","from autotrain import __version__\n","print(f'AutoTrain version: {__version__}')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:01:45.621155Z","iopub.status.busy":"2024-07-05T09:01:45.620803Z","iopub.status.idle":"2024-07-05T09:01:45.631904Z","shell.execute_reply":"2024-07-05T09:01:45.630724Z","shell.execute_reply.started":"2024-07-05T09:01:45.621130Z"},"trusted":true},"outputs":[],"source":["#@markdown ---\n","#@markdown #### Project Config\n","#@markdown Note: if you are using a restricted/private model, you need to enter your Hugging Face token in the next step.\n","project_name = 'llama3-8b-instruct-shroom' # @param {type:\"string\"}\n","model_name = 'meta-llama/Meta-Llama-3-8B-Instruct' # @param {type:\"string\"}\n","\n","#@markdown ---\n","#@markdown #### Push to Hub?\n","#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n","#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n","#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n","#@markdown You can find your token here: https://huggingface.co/settings/tokens\n","push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n","hf_token = \"HF_TOKEN\" #@param {type:\"string\"} ########### IMPORTANT ############\n","hf_username = \"HF_USERNAME\" #@param {type:\"string\"} ########### IMPORTANT ############\n","\n","#@markdown ---\n","#@markdown #### Hyperparameters\n","unsloth = False # @param [\"False\", \"True\"] {type:\"raw\"}\n","learning_rate = 2e-4 # @param {type:\"number\"}\n","num_epochs = 8 #@param {type:\"number\"}\n","batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n","block_size = 1024 # @param {type:\"number\"}\n","trainer = \"sft\" # @param [\"generic\", \"sft\"] {type:\"string\"}\n","warmup_ratio = 0.1 # @param {type:\"number\"}\n","weight_decay = 0.01 # @param {type:\"number\"}\n","gradient_accumulation = 4 # @param {type:\"number\"}\n","mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"string\"}\n","peft = True # @param [\"False\", \"True\"] {type:\"raw\"}\n","quantization = \"int4\" # @param [\"int4\", \"int8\", \"none\"] {type:\"string\"}\n","lora_r = 16 #@param {type:\"number\"}\n","lora_alpha = 32 #@param {type:\"number\"}\n","lora_dropout = 0.05 #@param {type:\"number\"}\n","\n","os.environ[\"HF_TOKEN\"] = hf_token\n","os.environ[\"HF_USERNAME\"] = hf_username\n","\n","conf = f\"\"\"\n","task: llm-{trainer}\n","base_model: {model_name}\n","project_name: {project_name}\n","log: tensorboard\n","backend: local\n","\n","data:\n","  path: data/\n","  train_split: train\n","  valid_split: null\n","  chat_template: null\n","  column_mapping:\n","    text_column: text\n","\n","params:\n","  block_size: {block_size}\n","  lr: {learning_rate}\n","  warmup_ratio: {warmup_ratio}\n","  weight_decay: {weight_decay}\n","  epochs: {num_epochs}\n","  batch_size: {batch_size}\n","  gradient_accumulation: {gradient_accumulation}\n","  mixed_precision: {mixed_precision}\n","  peft: {peft}\n","  quantization: {quantization}\n","  lora_r: {lora_r}\n","  lora_alpha: {lora_alpha}\n","  lora_dropout: {lora_dropout}\n","  unsloth: {unsloth}\n","\n","hub:\n","  username: ${{HF_USERNAME}}\n","  token: ${{HF_TOKEN}}\n","  push_to_hub: {push_to_hub}\n","\"\"\"\n","\n","with open(\"conf.yaml\", \"w\") as f:\n","    f.write(conf)"]},{"cell_type":"markdown","metadata":{},"source":["The following command will finetune the model and push it to your hub repository. It takes time (30 mins - 1 hour) My repository is [here](https://huggingface.co/arshandalili/llama3-8b-instruct-shroom)."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-04T18:23:11.766044Z","iopub.status.busy":"2024-07-04T18:23:11.765389Z","iopub.status.idle":"2024-07-04T18:41:29.339636Z","shell.execute_reply":"2024-07-04T18:41:29.338612Z","shell.execute_reply.started":"2024-07-04T18:23:11.766008Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:18\u001b[0m | \u001b[36mautotrain.cli.autotrain\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mUsing AutoTrain configuration: conf.yaml\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:18\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mRunning task: lm_training\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:18\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mUsing backend: local\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:18\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1m{'model': 'meta-llama/Meta-Llama-3-8B-Instruct', 'project_name': 'llama3-8b-instruct-shroom', 'data_path': 'data/', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'tensorboard', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 8, 'batch_size': 1, 'warmup_ratio': 0.1, 'gradient_accumulation': 4, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': None, 'text_column': 'text', 'rejected_text_column': None, 'push_to_hub': True, 'username': 'arshandalili', 'token': '*****', 'unsloth': False}\u001b[0m\n","Saving the dataset (1/1 shards): 100%|█| 499/499 [00:00<00:00, 141760.88 example\n","Saving the dataset (1/1 shards): 100%|█| 499/499 [00:00<00:00, 152859.90 example\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:18\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:18\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m400\u001b[0m - \u001b[1m['accelerate', 'launch', '--multi_gpu', '--num_machines', '1', '--num_processes', '2', '--mixed_precision', 'fp16', '-m', 'autotrain.trainers.clm', '--training_config', 'llama3-8b-instruct-shroom/training_params.json']\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:18\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1m{'model': 'meta-llama/Meta-Llama-3-8B-Instruct', 'project_name': 'llama3-8b-instruct-shroom', 'data_path': 'llama3-8b-instruct-shroom/autotrain-data', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'tensorboard', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 8, 'batch_size': 1, 'warmup_ratio': 0.1, 'gradient_accumulation': 4, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': 'autotrain_prompt', 'text_column': 'autotrain_text', 'rejected_text_column': 'autotrain_rejected_text', 'push_to_hub': True, 'username': 'arshandalili', 'token': '*****', 'unsloth': False}\u001b[0m\n","/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n","  warn(\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:31\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mStarting SFT training...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:31\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:31\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mTrain data: Dataset({\n","    features: ['Unnamed: 0', 'autotrain_text'],\n","    num_rows: 499\n","})\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:31\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m395\u001b[0m - \u001b[1mValid data: None\u001b[0m\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m467\u001b[0m - \u001b[1mconfiguring logging steps\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m480\u001b[0m - \u001b[1mLogging steps: 25\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_training_args\u001b[0m:\u001b[36m485\u001b[0m - \u001b[1mconfiguring training args\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_block_size\u001b[0m:\u001b[36m548\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m583\u001b[0m - \u001b[1mCan use unsloth: False\u001b[0m\n","\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m625\u001b[0m - \u001b[33m\u001b[1mUnsloth not available, continuing without it...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m627\u001b[0m - \u001b[1mloading model config...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:32\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m635\u001b[0m - \u001b[1mloading model...\u001b[0m\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","Loading checkpoint shards: 100%|██████████████████| 4/4 [00:25<00:00,  6.47s/it]\n","Loading checkpoint shards: 100%|██████████████████| 4/4 [00:25<00:00,  6.37s/it]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:59\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1mmodel dtype: torch.float16\u001b[0m\n","/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:23:59\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:181: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:181: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1961: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:24:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_train_begin\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mStarting to train...\u001b[0m\n"," 41%|█████████████████▋                         | 23/56 [07:03<10:09, 18.47s/it]\n","events.out.tfevents.1720115651.13b999f3fc5b.473.0:   0%| | 0.00/5.74k [00:00<?, \u001b[A\n","\n","events.out.tfevents.1720116201.13b999f3fc5b.689.0:   0%| | 0.00/6.50k [00:00<?, \u001b[A\u001b[A\n","\n","\n","Upload 3 LFS files:   0%|                                 | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","events.out.tfevents.1720117442.13b999f3fc5b.787.0: 100%|█| 5.74k/5.74k [00:00<00\u001b[A\u001b[A\u001b[A\u001b[A\n","events.out.tfevents.1720115651.13b999f3fc5b.473.0: 100%|█| 5.74k/5.74k [00:00<00\n","events.out.tfevents.1720116201.13b999f3fc5b.689.0: 100%|█| 6.50k/6.50k [00:00<00\n","\n","\n","\n","Upload 3 LFS files:  33%|████████▎                | 1/3 [00:00<00:00,  3.38it/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Upload 3 LFS files: 100%|█████████████████████████| 3/3 [00:00<00:00,  7.55it/s]\u001b[A\u001b[A\u001b[A\n"," 45%|███████████████████▏                       | 25/56 [07:41<09:39, 18.71s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:31:44\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 0.862, 'grad_norm': 0.33305811882019043, 'learning_rate': 0.000124, 'epoch': 3.225806451612903}\u001b[0m\n","{'loss': 0.862, 'grad_norm': 0.33305811882019043, 'learning_rate': 0.000124, 'epoch': 3.23}\n"," 89%|██████████████████████████████████████▍    | 50/56 [15:23<01:50, 18.45s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:39:25\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 0.4795, 'grad_norm': 0.508437991142273, 'learning_rate': 2.4e-05, 'epoch': 6.451612903225806}\u001b[0m\n","{'loss': 0.4795, 'grad_norm': 0.508437991142273, 'learning_rate': 2.4e-05, 'epoch': 6.45}\n","100%|███████████████████████████████████████████| 56/56 [17:13<00:00, 18.43s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:41:16\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'train_runtime': 1034.2528, 'train_samples_per_second': 0.48, 'train_steps_per_second': 0.054, 'train_loss': 0.6367850857121604, 'epoch': 7.225806451612903}\u001b[0m\n","{'train_runtime': 1034.2528, 'train_samples_per_second': 0.48, 'train_steps_per_second': 0.054, 'train_loss': 0.6367850857121604, 'epoch': 7.23}\n","100%|███████████████████████████████████████████| 56/56 [17:13<00:00, 18.46s/it]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:41:16\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mpost_training_steps\u001b[0m:\u001b[36m287\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:41:17\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mpost_training_steps\u001b[0m:\u001b[36m317\u001b[0m - \u001b[1mPushing model to hub...\u001b[0m\n","Upload 3 LFS files:   0%|                                 | 0/3 [00:00<?, ?it/s]\n","adapter_model.safetensors:   0%|                     | 0.00/168M [00:00<?, ?B/s]\u001b[A\n","\n","events.out.tfevents.1720117442.13b999f3fc5b.787.0:   0%| | 0.00/6.50k [00:00<?, \u001b[A\u001b[A\n","\n","\n","events.out.tfevents.1720117442.13b999f3fc5b.787.0: 100%|█| 6.50k/6.50k [00:00<00\u001b[A\u001b[A\u001b[A\n","\n","training_args.bin: 100%|███████████████████| 5.43k/5.43k [00:00<00:00, 39.3kB/s]\u001b[A\n","\n","adapter_model.safetensors:   9%|█▏          | 15.9M/168M [00:00<00:02, 75.9MB/s]\u001b[A\n","adapter_model.safetensors:  15%|█▊          | 24.5M/168M [00:00<00:02, 49.0MB/s]\u001b[A\n","adapter_model.safetensors:  19%|██▎         | 32.0M/168M [00:00<00:03, 36.6MB/s]\u001b[A\n","adapter_model.safetensors:  29%|███▍        | 48.0M/168M [00:01<00:02, 40.5MB/s]\u001b[A\n","adapter_model.safetensors:  35%|████▎       | 59.5M/168M [00:01<00:02, 51.2MB/s]\u001b[A\n","adapter_model.safetensors:  39%|████▋       | 66.0M/168M [00:01<00:02, 35.2MB/s]\u001b[A\n","adapter_model.safetensors:  45%|█████▍      | 75.5M/168M [00:01<00:02, 42.0MB/s]\u001b[A\n","adapter_model.safetensors:  48%|█████▊      | 81.2M/168M [00:02<00:03, 27.5MB/s]\u001b[A\n","adapter_model.safetensors:  55%|██████▌     | 91.5M/168M [00:02<00:02, 36.8MB/s]\u001b[A\n","adapter_model.safetensors:  58%|██████▉     | 97.4M/168M [00:02<00:02, 28.0MB/s]\u001b[A\n","adapter_model.safetensors:  64%|████████▎    | 107M/168M [00:02<00:01, 37.4MB/s]\u001b[A\n","adapter_model.safetensors:  68%|████████▊    | 114M/168M [00:03<00:01, 31.8MB/s]\u001b[A\n","adapter_model.safetensors:  76%|█████████▉   | 128M/168M [00:03<00:01, 36.0MB/s]\u001b[A\n","adapter_model.safetensors:  83%|██████████▊  | 140M/168M [00:03<00:00, 45.7MB/s]\u001b[A\n","adapter_model.safetensors:  87%|███████████▎ | 146M/168M [00:03<00:00, 36.1MB/s]\u001b[A\n","adapter_model.safetensors:  93%|████████████ | 156M/168M [00:04<00:00, 44.7MB/s]\u001b[A\n","adapter_model.safetensors: 100%|█████████████| 168M/168M [00:04<00:00, 37.5MB/s]\u001b[A\n","Upload 3 LFS files: 100%|█████████████████████████| 3/3 [00:04<00:00,  1.55s/it]\n","\u001b[1mINFO    \u001b[0m | \u001b[32m2024-07-04 18:41:28\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m199\u001b[0m - \u001b[1mJob ID: 778\u001b[0m\n"]}],"source":["! autotrain --config conf.yaml"]},{"cell_type":"markdown","metadata":{},"source":["## Inference"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the models"]},{"cell_type":"markdown","metadata":{},"source":["We now load the finetuned model and the tokenizer. Make sure to be authenticated to Hugging Face to load the model."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:05:16.914594Z","iopub.status.busy":"2024-07-05T09:05:16.913613Z","iopub.status.idle":"2024-07-05T09:07:06.852570Z","shell.execute_reply":"2024-07-05T09:07:06.851639Z","shell.execute_reply.started":"2024-07-05T09:05:16.914561Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcfb31592b86409c8a8f1d145b8ace20","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"928a7862c9a244ae866b1125d87db790","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ae3cdb224874b7ea3cac09cdbfd0078","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"faf89a48fa254b1b817101dd4a2d3d58","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21705301f8454031914bfe7adbbcc01c","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bc47a5ea1e341eba9f59be881d66594","version_major":2,"version_minor":0},"text/plain":["model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39d626d1ee934f7bb04e91c0271dbca3","version_major":2,"version_minor":0},"text/plain":["model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cae6eb94d58148b8abb7874814549e9f","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2323ed5ab4d441e9be7d61b9e3aae5fc","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"501fd2dfd7334e41956aa227269e00f9","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/738 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d8ae39de88d4b97a18728e72da2f863","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8629ae42201649c5ae69097e785dce17","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc1883faa9ab45e79b72512e15ffd6c9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ca0a27e58124ec0b1a3ab2aa51f7108","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","new_model = \"arshandalili/llama3-8b-instruct-shroom\"\n","\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n","    device_map='auto',\n",")\n","model = PeftModel.from_pretrained(base_model, new_model)\n","model = model.merge_and_unload()\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\""]},{"cell_type":"markdown","metadata":{},"source":["### Creating a pipeline for the model"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:45:07.744341Z","iopub.status.busy":"2024-07-05T09:45:07.743933Z","iopub.status.idle":"2024-07-05T09:45:07.749249Z","shell.execute_reply":"2024-07-05T09:45:07.748366Z","shell.execute_reply.started":"2024-07-05T09:45:07.744311Z"},"trusted":true},"outputs":[],"source":["pipe = pipeline(task=\"text-generation\", model=base_model, tokenizer=tokenizer, max_length=300, temperature=0.1)"]},{"cell_type":"markdown","metadata":{},"source":["## Results"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:41:22.689007Z","iopub.status.busy":"2024-07-05T09:41:22.688707Z","iopub.status.idle":"2024-07-05T09:41:22.770384Z","shell.execute_reply":"2024-07-05T09:41:22.769221Z","shell.execute_reply.started":"2024-07-05T09:41:22.688981Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>src</th>\n","      <th>tgt</th>\n","      <th>hyp</th>\n","      <th>task</th>\n","      <th>labels</th>\n","      <th>label</th>\n","      <th>p(Hallucination)</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Ты удивишься, если я скажу, что на самом деле ...</td>\n","      <td>Would you be surprised if I told you my name i...</td>\n","      <td>You're gonna be surprised if I say my real nam...</td>\n","      <td>MT</td>\n","      <td>['Not Hallucination', 'Not Hallucination', 'No...</td>\n","      <td>Not Hallucination</td>\n","      <td>0.0</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Еды будет полно.</td>\n","      <td>There will be plenty of food.</td>\n","      <td>The food will be full.</td>\n","      <td>MT</td>\n","      <td>['Hallucination', 'Not Hallucination', 'Halluc...</td>\n","      <td>Hallucination</td>\n","      <td>0.8</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>Думаете, Том будет меня ждать?</td>\n","      <td>Do you think that Tom will wait for me?</td>\n","      <td>You think Tom's gonna wait for me?</td>\n","      <td>MT</td>\n","      <td>['Not Hallucination', 'Not Hallucination', 'No...</td>\n","      <td>Not Hallucination</td>\n","      <td>0.2</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>Два брата довольно разные.</td>\n","      <td>The two brothers are pretty different.</td>\n","      <td>There's a lot of friends.</td>\n","      <td>MT</td>\n","      <td>['Hallucination', 'Hallucination', 'Hallucinat...</td>\n","      <td>Hallucination</td>\n","      <td>1.0</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>&lt;define&gt; Infradiaphragmatic &lt;/define&gt; intra- a...</td>\n","      <td>(medicine) Below the diaphragm.</td>\n","      <td>(anatomy) Relating to the diaphragm.</td>\n","      <td>DM</td>\n","      <td>['Hallucination', 'Hallucination', 'Hallucinat...</td>\n","      <td>Hallucination</td>\n","      <td>0.8</td>\n","      <td>### user: For the task DM Given a source sente...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  id                                                src  \\\n","0           0   1  Ты удивишься, если я скажу, что на самом деле ...   \n","1           1   2                                   Еды будет полно.   \n","2           2   3                     Думаете, Том будет меня ждать?   \n","3           3   6                         Два брата довольно разные.   \n","4           4   7  <define> Infradiaphragmatic </define> intra- a...   \n","\n","                                                 tgt  \\\n","0  Would you be surprised if I told you my name i...   \n","1                      There will be plenty of food.   \n","2            Do you think that Tom will wait for me?   \n","3             The two brothers are pretty different.   \n","4                    (medicine) Below the diaphragm.   \n","\n","                                                 hyp task  \\\n","0  You're gonna be surprised if I say my real nam...   MT   \n","1                             The food will be full.   MT   \n","2                 You think Tom's gonna wait for me?   MT   \n","3                          There's a lot of friends.   MT   \n","4               (anatomy) Relating to the diaphragm.   DM   \n","\n","                                              labels              label  \\\n","0  ['Not Hallucination', 'Not Hallucination', 'No...  Not Hallucination   \n","1  ['Hallucination', 'Not Hallucination', 'Halluc...      Hallucination   \n","2  ['Not Hallucination', 'Not Hallucination', 'No...  Not Hallucination   \n","3  ['Hallucination', 'Hallucination', 'Hallucinat...      Hallucination   \n","4  ['Hallucination', 'Hallucination', 'Hallucinat...      Hallucination   \n","\n","   p(Hallucination)                                               text  \n","0               0.0  ### user: For the task MT Given a source sente...  \n","1               0.8  ### user: For the task MT Given a source sente...  \n","2               0.2  ### user: For the task MT Given a source sente...  \n","3               1.0  ### user: For the task MT Given a source sente...  \n","4               0.8  ### user: For the task DM Given a source sente...  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["## Load the test dataset\n","\n","test_df = pd.read_csv('/kaggle/input/shroom/test_df_llm.csv')\n","test_df.head()"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:45:13.509799Z","iopub.status.busy":"2024-07-05T09:45:13.509126Z","iopub.status.idle":"2024-07-05T09:50:27.520582Z","shell.execute_reply":"2024-07-05T09:50:27.519794Z","shell.execute_reply.started":"2024-07-05T09:45:13.509769Z"},"trusted":true},"outputs":[],"source":["## Run the model on dataset (it will take a couple of minutes ~5-10 mins)\n","\n","result = pipe([f\"<s>[INST] {prompt} [/INST]\" for prompt in test_df['text'].tolist()])"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:55:37.971707Z","iopub.status.busy":"2024-07-05T09:55:37.970957Z","iopub.status.idle":"2024-07-05T09:55:37.985711Z","shell.execute_reply":"2024-07-05T09:55:37.984778Z","shell.execute_reply.started":"2024-07-05T09:55:37.971671Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1500/1500 [00:00<00:00, 479897.48it/s]\n"]},{"data":{"text/plain":["True"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["## Check if outputs are of good quality\n","\n","def check_ouput(data):\n","    for i in tqdm(data):\n","        if (i[0]['generated_text'].endswith(\"YES\") or i[0]['generated_text'].endswith(\"NO\")):\n","            continue\n","        else:\n","            return False\n","    return True\n","\n","check_ouput(result)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:57:30.832386Z","iopub.status.busy":"2024-07-05T09:57:30.831928Z","iopub.status.idle":"2024-07-05T09:57:30.846067Z","shell.execute_reply":"2024-07-05T09:57:30.845283Z","shell.execute_reply.started":"2024-07-05T09:57:30.832352Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1500/1500 [00:00<00:00, 471199.52it/s]\n"]}],"source":["## Extract the predictions\n","predictions = []\n","for i in tqdm(result):\n","        if i[0]['generated_text'].endswith(\"YES\"):\n","            predictions.append(1)\n","        elif i[0]['generated_text'].endswith(\"NO\"):\n","            predictions.append(0)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:58:00.575315Z","iopub.status.busy":"2024-07-05T09:58:00.574260Z","iopub.status.idle":"2024-07-05T09:58:00.583224Z","shell.execute_reply":"2024-07-05T09:58:00.582125Z","shell.execute_reply.started":"2024-07-05T09:58:00.575275Z"},"trusted":true},"outputs":[],"source":["test_df['prediction'] = predictions"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:58:05.930775Z","iopub.status.busy":"2024-07-05T09:58:05.930318Z","iopub.status.idle":"2024-07-05T09:58:05.949991Z","shell.execute_reply":"2024-07-05T09:58:05.948859Z","shell.execute_reply.started":"2024-07-05T09:58:05.930737Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>src</th>\n","      <th>tgt</th>\n","      <th>hyp</th>\n","      <th>task</th>\n","      <th>labels</th>\n","      <th>label</th>\n","      <th>p(Hallucination)</th>\n","      <th>text</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Ты удивишься, если я скажу, что на самом деле ...</td>\n","      <td>Would you be surprised if I told you my name i...</td>\n","      <td>You're gonna be surprised if I say my real nam...</td>\n","      <td>MT</td>\n","      <td>['Not Hallucination', 'Not Hallucination', 'No...</td>\n","      <td>Not Hallucination</td>\n","      <td>0.0</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Еды будет полно.</td>\n","      <td>There will be plenty of food.</td>\n","      <td>The food will be full.</td>\n","      <td>MT</td>\n","      <td>['Hallucination', 'Not Hallucination', 'Halluc...</td>\n","      <td>Hallucination</td>\n","      <td>0.8</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>Думаете, Том будет меня ждать?</td>\n","      <td>Do you think that Tom will wait for me?</td>\n","      <td>You think Tom's gonna wait for me?</td>\n","      <td>MT</td>\n","      <td>['Not Hallucination', 'Not Hallucination', 'No...</td>\n","      <td>Not Hallucination</td>\n","      <td>0.2</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>Два брата довольно разные.</td>\n","      <td>The two brothers are pretty different.</td>\n","      <td>There's a lot of friends.</td>\n","      <td>MT</td>\n","      <td>['Hallucination', 'Hallucination', 'Hallucinat...</td>\n","      <td>Hallucination</td>\n","      <td>1.0</td>\n","      <td>### user: For the task MT Given a source sente...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>&lt;define&gt; Infradiaphragmatic &lt;/define&gt; intra- a...</td>\n","      <td>(medicine) Below the diaphragm.</td>\n","      <td>(anatomy) Relating to the diaphragm.</td>\n","      <td>DM</td>\n","      <td>['Hallucination', 'Hallucination', 'Hallucinat...</td>\n","      <td>Hallucination</td>\n","      <td>0.8</td>\n","      <td>### user: For the task DM Given a source sente...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  id                                                src  \\\n","0           0   1  Ты удивишься, если я скажу, что на самом деле ...   \n","1           1   2                                   Еды будет полно.   \n","2           2   3                     Думаете, Том будет меня ждать?   \n","3           3   6                         Два брата довольно разные.   \n","4           4   7  <define> Infradiaphragmatic </define> intra- a...   \n","\n","                                                 tgt  \\\n","0  Would you be surprised if I told you my name i...   \n","1                      There will be plenty of food.   \n","2            Do you think that Tom will wait for me?   \n","3             The two brothers are pretty different.   \n","4                    (medicine) Below the diaphragm.   \n","\n","                                                 hyp task  \\\n","0  You're gonna be surprised if I say my real nam...   MT   \n","1                             The food will be full.   MT   \n","2                 You think Tom's gonna wait for me?   MT   \n","3                          There's a lot of friends.   MT   \n","4               (anatomy) Relating to the diaphragm.   DM   \n","\n","                                              labels              label  \\\n","0  ['Not Hallucination', 'Not Hallucination', 'No...  Not Hallucination   \n","1  ['Hallucination', 'Not Hallucination', 'Halluc...      Hallucination   \n","2  ['Not Hallucination', 'Not Hallucination', 'No...  Not Hallucination   \n","3  ['Hallucination', 'Hallucination', 'Hallucinat...      Hallucination   \n","4  ['Hallucination', 'Hallucination', 'Hallucinat...      Hallucination   \n","\n","   p(Hallucination)                                               text  \\\n","0               0.0  ### user: For the task MT Given a source sente...   \n","1               0.8  ### user: For the task MT Given a source sente...   \n","2               0.2  ### user: For the task MT Given a source sente...   \n","3               1.0  ### user: For the task MT Given a source sente...   \n","4               0.8  ### user: For the task DM Given a source sente...   \n","\n","   prediction  \n","0           0  \n","1           1  \n","2           1  \n","3           1  \n","4           1  "]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_df.to_csv('test_df_LLM.csv')"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T09:59:51.142678Z","iopub.status.busy":"2024-07-05T09:59:51.142314Z","iopub.status.idle":"2024-07-05T09:59:51.164102Z","shell.execute_reply":"2024-07-05T09:59:51.163049Z","shell.execute_reply.started":"2024-07-05T09:59:51.142650Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.85      0.61      0.71       889\n","           1       0.60      0.84      0.70       611\n","\n","    accuracy                           0.70      1500\n","   macro avg       0.72      0.73      0.70      1500\n","weighted avg       0.75      0.70      0.71      1500\n","\n"]}],"source":["## Evaluate the model\n","test_labels = [1 if x > 0.5 else 0 for x in test_df['p(Hallucination)'].tolist()]\n","\n","print(classification_report(test_labels, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["## Results for each task"]},{"cell_type":"markdown","metadata":{},"source":["### DM"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T10:01:40.082792Z","iopub.status.busy":"2024-07-05T10:01:40.081928Z","iopub.status.idle":"2024-07-05T10:01:40.101664Z","shell.execute_reply":"2024-07-05T10:01:40.100664Z","shell.execute_reply.started":"2024-07-05T10:01:40.082750Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DM Task Results: \n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.39      0.54       275\n","           1       0.62      0.95      0.75       288\n","\n","    accuracy                           0.68       563\n","   macro avg       0.76      0.67      0.65       563\n","weighted avg       0.75      0.68      0.65       563\n","\n"]}],"source":["## Get the rows where task is DM\n","test_df_dm = test_df[test_df['task'] == 'DM']\n","y_test_dm = np.array(test_df_dm['p(Hallucination)'].tolist())\n","y_pred_dm = np.array(test_df_dm['prediction'].tolist())\n","test_labels_dm = [1 if x > 0.5 else 0 for x in y_test_dm]\n","print(\"DM Task Results: \")\n","print(classification_report(test_labels_dm, y_pred_dm))"]},{"cell_type":"markdown","metadata":{},"source":["### MT"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T10:03:02.305671Z","iopub.status.busy":"2024-07-05T10:03:02.305032Z","iopub.status.idle":"2024-07-05T10:03:02.323265Z","shell.execute_reply":"2024-07-05T10:03:02.322248Z","shell.execute_reply.started":"2024-07-05T10:03:02.305639Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["MT Task Results: \n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.74      0.77       336\n","           1       0.66      0.75      0.70       226\n","\n","    accuracy                           0.74       562\n","   macro avg       0.74      0.74      0.74       562\n","weighted avg       0.75      0.74      0.74       562\n","\n"]}],"source":["## Get the rows where task is MT\n","test_df_mt = test_df[test_df['task'] == 'MT']\n","y_test_mt = np.array(test_df_mt['p(Hallucination)'].tolist())\n","y_pred_mt = np.array(test_df_mt['prediction'].tolist())\n","test_labels_mt = [1 if x > 0.5 else 0 for x in y_test_mt]\n","print(\"MT Task Results: \")\n","print(classification_report(test_labels_mt, y_pred_mt))"]},{"cell_type":"markdown","metadata":{},"source":["### PG"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-07-05T10:04:30.707824Z","iopub.status.busy":"2024-07-05T10:04:30.706962Z","iopub.status.idle":"2024-07-05T10:04:30.725309Z","shell.execute_reply":"2024-07-05T10:04:30.724282Z","shell.execute_reply.started":"2024-07-05T10:04:30.707788Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PG Task Results: \n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.68      0.76       278\n","           1       0.44      0.70      0.54        97\n","\n","    accuracy                           0.69       375\n","   macro avg       0.65      0.69      0.65       375\n","weighted avg       0.76      0.69      0.71       375\n","\n"]}],"source":["## Get the rows where task is PG\n","test_df_pg = test_df[test_df['task'] == 'PG']\n","y_test_pg = np.array(test_df_pg['p(Hallucination)'].tolist())\n","y_pred_pg = np.array(test_df_pg['prediction'].tolist())\n","test_labels_pg = [1 if x > 0.5 else 0 for x in y_test_pg]\n","print(\"PG Task Results: \")\n","print(classification_report(test_labels_pg, y_pred_pg))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5332531,"sourceId":8868495,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
